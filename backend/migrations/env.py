import os
import sys
from logging.config import fileConfig

import sqlalchemy as sa
from alembic import context
from alembic.autogenerate import rewriter
from alembic.operations import ops

from project.core.settings import engine as engine
from project.core.settings import settings

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
writer = rewriter.Rewriter()

sys.path.append(BASE_DIR)

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# this will overwrite the ini-file sqlalchemy.url path
# with the path given in the config of the main code
config.set_main_option("sqlalchemy.url", settings.database_url)

# Interpret the config file for Python logging.
# This line sets up loggers basically.
fileConfig(config.config_file_name)  # type: ignore

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel

from project.core.db import models  # noqa: E402

# target_metadata = mymodel.Base.metadata
# here target_metadata was equal to None
target_metadata = models.Base.metadata


# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


@writer.rewrites(ops.CreateTableOp)
def order_columns(context, revision, op):
    """Rewrites order of columns for autogenerated migrations."""
    special_names = {"id": -100, "created_at": 1001, "updated_at": 1002}

    cols_by_key = [
        (
            special_names.get(col.key, index) if isinstance(col, sa.Column) else 2000,
            col.copy(),
        )
        for index, col in enumerate(op.columns)
    ]

    columns = [col for idx, col in sorted(cols_by_key, key=lambda entry: entry[0])]
    return ops.CreateTableOp(op.table_name, columns, schema=op.schema, _namespace_metadata=op._namespace_metadata)


def run_migrations_offline():
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        process_revision_directives=writer,
    )

    with context.begin_transaction():
        context.run_migrations()


async def run_migrations_online():
    def do_migrations(connection):
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            process_revision_directives=writer,
        )

        with context.begin_transaction():
            context.run_migrations()

    async with engine.connect() as connection:
        await connection.run_sync(do_migrations)

    await engine.dispose()


if context.is_offline_mode():
    run_migrations_offline()
else:
    import asyncio

    asyncio.run(run_migrations_online())
